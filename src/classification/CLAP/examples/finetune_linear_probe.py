"""
ESC-50 Linear Probing with CLAP
ä½¿ç”¨é¢„è®­ç»ƒçš„ CLAP æå–ç‰¹å¾ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨

ç­–ç•¥ï¼š
1. å†»ç»“ CLAP ç¼–ç å™¨ï¼ˆä¸æ›´æ–°æƒé‡ï¼‰
2. ä½¿ç”¨ 4 ä¸ª fold è®­ç»ƒï¼Œ1 ä¸ª fold æµ‹è¯•ï¼ˆ5-fold CVï¼‰
3. åªè®­ç»ƒä¸€ä¸ªç®€å•çš„çº¿æ€§åˆ†ç±»å™¨
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from msclap import CLAP
from esc50_dataset import ESC50
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import pandas as pd

# ===== é…ç½® =====
BATCH_SIZE = 32
NUM_EPOCHS = 50
LEARNING_RATE = 0.001
USE_CUDA = torch.cuda.is_available()
TEST_FOLD = 5  # ä½¿ç”¨ fold 5 ä½œä¸ºæµ‹è¯•é›†ï¼Œfold 1-4 ä½œä¸ºè®­ç»ƒé›†

print("="*60)
print("ESC-50 Linear Probing with CLAP")
print("="*60)
print(f"Device: {'GPU' if USE_CUDA else 'CPU'}")
print(f"Test Fold: {TEST_FOLD}")
print(f"Training Folds: {[i for i in range(1, 6) if i != TEST_FOLD]}")
print("="*60)

# ===== åŠ è½½æ•°æ®é›† =====
root_path = "/home/linfeng_fan/DSP-HW/ESC-50"
dataset = ESC50(root=root_path, download=False)

# è¯»å– fold ä¿¡æ¯
meta_df = pd.read_csv(f"{root_path}/meta/esc50.csv")

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_indices = meta_df[meta_df['fold'] != TEST_FOLD].index.tolist()
test_indices = meta_df[meta_df['fold'] == TEST_FOLD].index.tolist()

train_dataset = Subset(dataset, train_indices)
test_dataset = Subset(dataset, test_indices)

print(f"\nDataset size:")
print(f"  Training: {len(train_dataset)} samples")
print(f"  Testing: {len(test_dataset)} samples")

# ===== åŠ è½½ CLAP æ¨¡å‹ =====
print("\nLoading CLAP model...")
clap_model = CLAP(version='2023', use_cuda=USE_CUDA)

# å†»ç»“ CLAP å‚æ•°
for param in clap_model.clap.parameters():
    param.requires_grad = False

clap_model.clap.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

# ===== æå–ç‰¹å¾ =====
def extract_features(dataset, model, desc="Extracting features"):
    """æå–éŸ³é¢‘çš„ CLAP embeddings"""
    features = []
    labels = []

    for i in tqdm(range(len(dataset)), desc=desc):
        audio_path, label_str, one_hot = dataset[i]

        # æå–éŸ³é¢‘ embedding
        with torch.no_grad():
            audio_emb = model.get_audio_embeddings([audio_path], resample=True)

        features.append(audio_emb.cpu())
        labels.append(torch.argmax(one_hot).item())

    features = torch.cat(features, dim=0)
    labels = torch.tensor(labels)

    return features, labels

print("\n" + "="*60)
print("Extracting CLAP features...")
print("="*60)

train_features, train_labels = extract_features(train_dataset, clap_model, "Training set")
test_features, test_labels = extract_features(test_dataset, clap_model, "Test set")

print(f"\nFeature shapes:")
print(f"  Train features: {train_features.shape}")
print(f"  Train labels: {train_labels.shape}")
print(f"  Test features: {test_features.shape}")
print(f"  Test labels: {test_labels.shape}")

# ===== å®šä¹‰çº¿æ€§åˆ†ç±»å™¨ =====
class LinearClassifier(nn.Module):
    def __init__(self, input_dim, num_classes):
        super().__init__()
        self.fc = nn.Linear(input_dim, num_classes)

    def forward(self, x):
        return self.fc(x)

# åˆ›å»ºåˆ†ç±»å™¨
input_dim = train_features.shape[1]
num_classes = 50
classifier = LinearClassifier(input_dim, num_classes)

if USE_CUDA:
    classifier = classifier.cuda()
    train_features = train_features.cuda()
    train_labels = train_labels.cuda()
    test_features = test_features.cuda()
    test_labels = test_labels.cuda()

# ===== è®­ç»ƒ =====
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=LEARNING_RATE)

print("\n" + "="*60)
print("Training Linear Classifier...")
print("="*60)

best_acc = 0.0
best_epoch = 0

for epoch in range(NUM_EPOCHS):
    classifier.train()

    # è®­ç»ƒ
    optimizer.zero_grad()
    outputs = classifier(train_features)
    loss = criterion(outputs, train_labels)
    loss.backward()
    optimizer.step()

    # è¯„ä¼°
    classifier.eval()
    with torch.no_grad():
        # è®­ç»ƒé›†å‡†ç¡®ç‡
        train_outputs = classifier(train_features)
        train_preds = torch.argmax(train_outputs, dim=1)
        train_acc = (train_preds == train_labels).float().mean().item()

        # æµ‹è¯•é›†å‡†ç¡®ç‡
        test_outputs = classifier(test_features)
        test_preds = torch.argmax(test_outputs, dim=1)
        test_acc = (test_preds == test_labels).float().mean().item()

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if test_acc > best_acc:
        best_acc = test_acc
        best_epoch = epoch + 1
        torch.save(classifier.state_dict(), 'best_linear_classifier.pth')

    # æ¯5ä¸ªepochæ‰“å°ä¸€æ¬¡
    if (epoch + 1) % 5 == 0:
        print(f"Epoch [{epoch+1:3d}/{NUM_EPOCHS}] | "
              f"Loss: {loss.item():.4f} | "
              f"Train Acc: {train_acc*100:.2f}% | "
              f"Test Acc: {test_acc*100:.2f}%")

# ===== æœ€ç»ˆè¯„ä¼° =====
print("\n" + "="*60)
print("Final Results")
print("="*60)

# åŠ è½½æœ€ä½³æ¨¡å‹
classifier.load_state_dict(torch.load('best_linear_classifier.pth'))
classifier.eval()

with torch.no_grad():
    test_outputs = classifier(test_features)
    test_preds = torch.argmax(test_outputs, dim=1)
    final_acc = (test_preds == test_labels).float().mean().item()

print(f"\nğŸ† Best Test Accuracy: {best_acc*100:.2f}% (Epoch {best_epoch})")
print(f"ğŸ“Š Final Test Accuracy: {final_acc*100:.2f}%")
print(f"\nâœ… Model saved to: best_linear_classifier.pth")

print("\n" + "="*60)
print("Comparison with Zero-shot")
print("="*60)
print(f"Zero-shot (optimized):  94.35%")
print(f"Linear Probing:         {final_acc*100:.2f}%")
print(f"Improvement:            +{(final_acc*100 - 94.35):.2f}%")
print("="*60)
